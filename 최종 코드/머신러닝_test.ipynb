{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967fb184-41cc-465d-82b6-e25fe59a2890",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df74a6-0ec1-4a50-9233-09018210551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('../최종 파일/84data_final.xlsx', index_col=0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7000be79-df55-4ae9-9623-f45ba19275ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel('../최종 파일/85data_final.xlsx', index_col=0)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e06b487-a0d2-4a60-a0fa-44d98fccb333",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_85 = df2['product']\n",
    "df_85 = pd.DataFrame({'hs code':df2['hs code'], 'description':df2['description'], 'reason':df2['reason'], 'name_des':df2['name_des']})\n",
    "df_85.insert(1, 'product', product_85)\n",
    "df_85.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a48ee7-c94b-47d3-911e-e3eb6671dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df_85])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf9bf5-8d74-4529-8ce8-93d5723c9a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['hs code'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a170b461-4f78-4460-bd6c-4e60cf45c716",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd50e0-50ed-4531-b785-039205bf082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')  # pos_tag를 위한 데이터 다운로드\n",
    "\n",
    "# Initialize WordNet Lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.append('x')\n",
    "stop_words.append('w')\n",
    "\n",
    "lemmatized_des = []\n",
    "for i in df['name_des']:\n",
    "    # 텍스트 전처리: 소문자 변환, 토큰화, 불용어 제거\n",
    "    tokens = word_tokenize(i.lower())\n",
    "    tagged_tokens = nltk.pos_tag(tokens)  # 단어 토큰에 품사 태깅 추가\n",
    "\n",
    "    # 품사를 고려하여 단어의 원형 복원 (명사와 동사만 고려)\n",
    "    filtered_tokens = []\n",
    "    for word, tag in tagged_tokens:\n",
    "        if (tag.startswith('NN') or tag.startswith('VB')) and word not in stop_words:  # 명사 또는 동사인 경우\n",
    "            lemma = lemmatizer.lemmatize(word, pos='n' if tag.startswith('NN') else 'v')\n",
    "            filtered_tokens.append(lemma)\n",
    "        elif word.isalpha() and word not in stop_words:\n",
    "            filtered_tokens.append(word)\n",
    "    lemmatized_des.append(' '.join(filtered_tokens))\n",
    "\n",
    "print(lemmatized_des[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624a1a1-b08c-4cf4-b244-87a99e8226f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = pd.DataFrame({'hs code': df['hs code'], 'name_des':lemmatized_des})\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bc2904-a0ee-46b0-955c-546cd08ffeab",
   "metadata": {},
   "source": [
    "# 종속변수, 독립변수 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e5a99a-d21f-4404-875e-a4765f3ced9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocessed_df['name_des']\n",
    "y_train = preprocessed_df['hs code']\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2863007f-8017-409e-b899-9334f9ad33d3",
   "metadata": {},
   "source": [
    "# 벡터라이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5359b06-d5cf-41ca-8969-e851a6b4a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf_vec.fit(x_train)\n",
    "x_train_tfidf_vec = tfidf_vec.transform(x_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e100a-6a88-4f5a-89f6-9de2c63ce09b",
   "metadata": {},
   "source": [
    "# 모델 학습 - LSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c213a0-7e42-4459-a8ef-c56ca0320fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,classification_report\n",
    "\n",
    "svc = LinearSVC(C=1)\n",
    "svc.fit(x_train_tfidf_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce9897-a792-4300-ab9e-a194211049bd",
   "metadata": {},
   "source": [
    "# 모델 학습 - 랜덤 포레스트\n",
    "- 파라메터값은 정확히 모르겠어서 수정 부탁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ae1ec6-6471-4d25-a1d1-f49f7963cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rmc =RandomForestClassifier(n_estimators=1000, max_depth=500)\n",
    "rmc.fit(x_train_tfidf_vec,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c24adf-1486-40f2-8fd9-905a83907037",
   "metadata": {},
   "source": [
    "# 모델 학습 - 로지스틱회귀분류\n",
    "- 파라메터값은 정확히 모르겠어서 수정 부탁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977b823-4530-4d65-96af-fb130a319be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', multi_class='ovr')\n",
    "lr.fit(x_train_tfidf_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e42572-7aac-4802-b553-53e13341ec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피클로 모델 저장\n",
    "import pickle\n",
    "\n",
    "with open('./drive/MyDrive/DIMA3/lsvc.pkl', 'wb') as file:\n",
    "    pickle.dump(lsvc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643f4499-19e9-4d0d-ada2-3e16f1fb6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./drive/MyDrive/DIMA3/lsvc.pkl', 'wb') as file:\n",
    "    pickle.dump(rmc, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57253182-ba91-494d-898f-82b65646de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./drive/MyDrive/DIMA3/lsvc.pkl', 'wb') as file:\n",
    "    pickle.dump(lr, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bc27e-bea9-4474-85de-2d3efea41019",
   "metadata": {},
   "source": [
    "# 테스트 데이터 적용 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae84240-86f7-4fa9-b3b2-6d79a8eebaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('../최종 파일/usa_test_data.xlsx', index_col=0)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57eb1a-4ea9-4b4e-a58a-4e2b111ea864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 인덱스 값 맞추기\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79de97-fe9a-4415-9800-ef0d5b52b1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 적용된 벡터라이저로 테스트 데이터에도 적용\n",
    "test_tfidf_vec = tfidf_vec.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67358d-765f-4c35-ad72-447bc9ef3202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리된 테스트 데이터를 예측 모델에 적용\n",
    "y_hat_lsvc = svc.predict(test_tfidf_vec)\n",
    "#y_hat_rmc = rmc.predict(test_tfidf_vec)\n",
    "y_hat_lr = lr.predict(test_tfidf_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26867456-df6a-46ed-a8d6-4ae901bdb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSVC 정확도 체크\n",
    "cnt = 0\n",
    "for i, v in zip(test['hs code'], y_hat_lsvc):\n",
    "    print(i, v)\n",
    "    if i == v:\n",
    "        cnt += 1\n",
    "\n",
    "print('LSVC 정확도:', cnt/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f0884-d909-43bc-a7f3-3ff58f3655dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier 정확도 체크\n",
    "cnt = 0\n",
    "for i, v in zip(test['hs code'], y_hat_rmc):\n",
    "    if i == v:\n",
    "        cnt += 1\n",
    "\n",
    "print('LSVC 정확도:', cnt/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfdbea0-7a85-41bf-af9a-f2c6f54a1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression 정확도 체크\n",
    "cnt = 0\n",
    "for i, v in zip(test['hs code'], y_hat_lr):\n",
    "    if i == v:\n",
    "        cnt += 1\n",
    "\n",
    "print('LSVC 정확도:', cnt/len(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
